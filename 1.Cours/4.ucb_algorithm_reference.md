# Algorithme UCB (Upper Confidence Bounds)

## Vue d'ensemble

L'algorithme **UCB** (Upper Confidence Bounds) résout le dilemme fondamental entre **exploitation** et **exploration** dans les problèmes de bandits à bras multiples. Dans le contexte des jeux, il sélectionne intelligemment les coups à étudier en équilibrant les moves prometteurs (exploitation) avec l'exploration de nouvelles possibilités.

## Le problème des bandits à bras multiples

### Analogie du casino
Imaginez un casino avec plusieurs machines à sous (bandits) :
- Chaque machine a un taux de gain différent (inconnu)
- Vous devez maximiser vos gains totaux
- **Dilemme** : Continuer à jouer la meilleure machine trouvée ou tester les autres ?

### Application aux jeux
- **Bras** = Coups possibles depuis une position
- **Récompense** = Résultat de simulation (0 ou 1)
- **Objectif** = Trouver le meilleur coup en minimisant les regrets

## Formule UCB1

```
UCB1 = X̄ⱼ + √(2 ln n / nⱼ)
```

**Où** :
- `X̄ⱼ` : Récompense moyenne du coup j (exploitation)
- `n` : Nombre total de simulations effectuées
- `nⱼ` : Nombre de fois que le coup j a été testé
- `√(2 ln n / nⱼ)` : Terme d'exploration

## Analyse du code

### Structure des données

```python
moves = board.legalMoves()
sumScores = [0.0 for x in range(len(moves))]  # Somme des récompenses
nbVisits = [0 for x in range(len(moves))]     # Nombre de visites
```

- `sumScores[m]` : Accumule les résultats pour le coup m
- `nbVisits[m]` : Compte les essais du coup m

### Boucle principale (n itérations)

```python
for i in range(n):
    bestScore = 0
    bestMove = 0
    for m in range(len(moves)):
        score = 1000000  # Valeur infinie pour coups inexplorés
        if nbVisits[m] > 0:
            # Formule UCB1 modifiée
            score = sumScores[m]/nbVisits[m] + 0.4*sqrt(log(i)/nbVisits[m])
        if score > bestScore:
            bestScore = score
            bestMove = m
```

#### Calcul du score UCB
1. **Coups jamais testés** : `score = 1000000` (priorité maximale)
2. **Coups déjà testés** : Formule UCB avec constante `0.4`

**Formule utilisée** :
```
score = moyenne + 0.4 * √(ln(i) / visites)
```

### Simulation et mise à jour

```python
b = copy.deepcopy(board)      # Copie pour simulation
b.play(moves[bestMove])       # Joue le coup sélectionné
r = b.playout()               # Simulation aléatoire jusqu'à la fin

# Normalisation selon le joueur
if board.turn == Black:
    r = 1.0 - r               # Inverse pour les Noirs

# Mise à jour des statistiques
sumScores[bestMove] += r      # Accumule la récompense
nbVisits[bestMove] += 1       # Incrémente le compteur
```

### Sélection finale

```python
bestNbVisits = 0
bestMove = 0
for m in range(len(moves)):
    if nbVisits[m] > bestNbVisits:  # Coup le plus visité
        bestNbVisits = nbVisits[m]
        bestMove = m
return moves[bestMove]
```

**Stratégie finale** : Retourne le coup ayant reçu le plus de simulations.

## Mécanisme d'équilibrage

### Terme d'exploitation : `X̄ⱼ`
- **Haute valeur** → Coup historiquement bon → Plus probable d'être sélectionné
- Favorise les coups avec de bons résultats passés

### Terme d'exploration : `√(2 ln n / nⱼ)`
- **Augmente** avec le nombre total de simulations (`n`)
- **Diminue** avec le nombre de tests du coup (`nⱼ`)
- Favorise les coups peu explorés

### Constante d'exploration : `0.4`
- **Plus élevée** → Plus d'exploration, moins de focus
- **Plus basse** → Plus d'exploitation, risque de rater de bons coups
- Valeur empirique optimisée pour les jeux

## Exemple concret

### Situation : 3 coups possibles après 10 itérations

| Coup | Visites | Score total | Moyenne | Exploration | UCB Score |
|------|---------|-------------|---------|-------------|-----------|
| A    | 5       | 3.2         | 0.64    | 0.4×√(ln10/5) ≈ 0.22 | 0.86 |
| B    | 3       | 1.8         | 0.60    | 0.4×√(ln10/3) ≈ 0.28 | 0.88 |
| C    | 2       | 1.1         | 0.55    | 0.4×√(ln10/2) ≈ 0.34 | 0.89 |

**Résultat** : Le coup C sera sélectionné (score UCB le plus élevé) malgré sa moyenne plus faible, car il nécessite plus d'exploration.

## Propriétés théoriques

### Convergence garantie
- **Regret** borné logarithmiquement : O(ln n)
- Tous les coups sont explorés infiniment souvent
- Convergence vers l'optimal avec suffisamment d'itérations

### Regret minimal
Le regret après n essais suit :
```
R(n) ≤ 8 Σⱼ (ln n / Δⱼ) + (1 + π²/3) Σⱼ Δⱼ
```
Où `Δⱼ` est l'écart entre la récompense optimale et celle du bras j.

## Comparaison avec d'autres approches

### Vs Flat Monte Carlo
| Aspect | Flat MC | UCB |
|--------|---------|-----|
| **Allocation** | Uniforme | Adaptative |
| **Efficacité** | Faible | Élevée |
| **Convergence** | Lente | Rapide |
| **Complexité** | Simple | Modérée |

### Vs ε-greedy
- **ε-greedy** : Exploration aléatoire avec probabilité ε
- **UCB** : Exploration dirigée basée sur l'incertitude
- **Avantage UCB** : Exploration plus intelligente, pas de paramètre ε à régler

## Variantes et améliorations

### UCB1-Tuned
```
UCB1-Tuned = X̄ⱼ + √(ln n / nⱼ × min{1/4, Vⱼ(nⱼ)})
```
Utilise la variance empirique pour améliorer les bornes.

### UCT (UCB for Trees)
Extension d'UCB aux arbres de recherche :
```
UCT = X̄ⱼ + Cp√(2 ln n / nⱼ)
```
Avec constante d'exploration Cp ajustable.

### Bayesian UCB
Incorpore des priors bayésiens pour de meilleures estimations avec peu d'échantillons.

## Applications pratiques

### Jeux de stratégie
- **Go** : Sélection de coups dans MCTS
- **Chess** : Exploration d'arbres de recherche
- **Poker** : Optimisation de stratégies

### Autres domaines
- **Publicité en ligne** : Sélection de bannières
- **Tests A/B** : Allocation de trafic
- **Recommandation** : Équilibrage nouveauté/pertinence

## Paramètres d'optimisation

### Constante d'exploration
```python
# Valeurs typiques
exploration_constant = 0.4   # Jeux classiques
exploration_constant = √2    # Théorie UCB1
exploration_constant = 1.41  # Valeur courante
```

### Critères d'arrêt
- **Nombre fixe** : 1000, 10000 itérations
- **Temps limité** : 5 secondes par coup
- **Convergence** : Écart-type des scores < seuil

## Implémentation optimisée

```python
def UCB_optimized(board, n, exploration=0.4):
    moves = board.legalMoves()
    if len(moves) == 1:
        return moves[0]  # Un seul coup possible
    
    # Initialisation
    stats = [(0.0, 0) for _ in moves]  # (sum_rewards, visits)
    
    for i in range(1, n + 1):  # Commence à 1 pour éviter ln(0)
        best_move_idx = 0
        best_ucb = float('-inf')
        
        for j, (sum_reward, visits) in enumerate(stats):
            if visits == 0:
                ucb_score = float('inf')  # Priorité absolue
            else:
                avg_reward = sum_reward / visits
                confidence = exploration * math.sqrt(math.log(i) / visits)
                ucb_score = avg_reward + confidence
            
            if ucb_score > best_ucb:
                best_ucb = ucb_score
                best_move_idx = j
        
        # Simulation
        temp_board = copy.deepcopy(board)
        temp_board.play(moves[best_move_idx])
        reward = temp_board.playout()
        
        if board.turn == Black:
            reward = 1.0 - reward
        
        # Mise à jour
        old_sum, old_visits = stats[best_move_idx]
        stats[best_move_idx] = (old_sum + reward, old_visits + 1)
    
    # Retourne le coup le plus visité
    _, best_idx = max((visits, i) for i, (_, visits) in enumerate(stats))
    return moves[best_idx]
```

## Limites et considérations

### Hypothèses du modèle
- **Récompenses bornées** [0,1]
- **Distribution stationnaire** (les probabilités ne changent pas)
- **Indépendance** des essais

### Problèmes pratiques
- **Démarrage à froid** : Premiers essais purement exploratoires
- **Constante d'exploration** : Difficile à régler optimalement
- **Horizon fini** : Performances sous-optimales si n est petit

## Conclusion

L'algorithme UCB représente une solution élégante au dilemme exploitation-exploration. Sa simplicité d'implémentation, ses garanties théoriques et son efficacité pratique en font un choix privilégié pour de nombreuses applications d'IA, particulièrement dans les jeux où il constitue la base d'algorithmes plus sophistiqués comme UCT/MCTS.